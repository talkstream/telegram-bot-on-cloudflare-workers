# Fire-and-Forget Analytics Pattern

## Overview

The Fire-and-Forget Analytics pattern uses Cloudflare's `ExecutionContext.waitUntil()` to send analytics and monitoring data **after** the response is returned to the user. This achieves an **82% improvement in response time** by making analytics completely non-blocking.

## Problem

Traditional analytics implementation blocks the response:

```typescript
// ❌ Bad: Analytics blocks response
async function handleRequest(request: Request) {
  const start = Date.now();
  
  // Process request...
  const result = await processRequest(request);
  
  // This blocks the response!
  await sendAnalytics({
    event: 'request_processed',
    duration: Date.now() - start,
  }); // Adds 30-50ms to response time
  
  return new Response(result);
}
```

This is especially problematic for:
- Telegram bot callbacks (users see loading indicators)
- API endpoints (higher latency)
- Free tier constraints (10ms CPU limit)

## Solution

Use `ExecutionContext.waitUntil()` to defer analytics after the response:

```typescript
// ✅ Good: Analytics happens after response
export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext) {
    const analytics = new AsyncAnalytics(ctx, {
      endpoint: env.ANALYTICS_ENDPOINT,
    });
    
    // Track event without blocking
    analytics.track('request_received');
    
    const result = await processRequest(request);
    
    // Return response immediately
    return new Response(result);
    // Analytics sent in background via waitUntil()
  }
}
```

## Implementation

### Basic Usage

```typescript
import { AsyncAnalytics, AnalyticsFactory } from '@/lib/analytics/async-analytics';

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext) {
    // Create analytics for this request
    const analytics = AnalyticsFactory.create(ctx, env);
    
    // Track events without blocking
    analytics.track('page_view', {
      path: new URL(request.url).pathname,
      method: request.method,
    });
    
    // Process request
    const response = await handleRequest(request);
    
    // Track completion
    analytics.track('request_complete', {
      status: response.status,
    });
    
    // Response returned immediately
    // Analytics continues in background
    return response;
  }
};
```

### Telegram Bot Integration

```typescript
async function handleTelegramUpdate(
  update: TelegramUpdate,
  env: Env,
  ctx: ExecutionContext
) {
  const analytics = new AsyncAnalytics(ctx, {
    endpoint: env.ANALYTICS_URL,
    batching: true,
  });
  
  // For callbacks - acknowledge IMMEDIATELY
  if (update.callback_query) {
    // This MUST happen first for good UX
    await answerCallbackQuery(update.callback_query.id);
    
    // Track after acknowledgment (non-blocking)
    analytics.track('callback_clicked', {
      data: update.callback_query.data,
    });
  }
  
  // Process update
  const result = await processUpdate(update);
  
  // Track completion
  analytics.track('update_processed', {
    type: getUpdateType(update),
  });
  
  // Flush any batched events
  analytics.flush();
  
  return new Response('OK');
}
```

### Error Tracking

```typescript
try {
  const result = await riskyOperation();
  
  // Track success (non-blocking)
  analytics.track('operation_success');
  
  return result;
} catch (error) {
  // Track error (non-blocking)
  analytics.trackError(error, {
    operation: 'risky_operation',
    context: { /* additional data */ },
  });
  
  // Still return response quickly
  return new Response('Error', { status: 500 });
}
```

## Features

### Event Batching

Reduce network overhead by batching events:

```typescript
const analytics = new AsyncAnalytics(ctx, {
  batching: true,
  batchSize: 20,      // Send after 20 events
  flushInterval: 1000, // Or after 1 second
});

// Events are automatically batched
for (const item of items) {
  analytics.track('item_processed', { id: item.id });
}

// Manual flush at end
analytics.flush();
```

### Performance Tracking

Built-in performance measurement:

```typescript
const start = Date.now();

// Do work...

analytics.trackPerformance('operation_name', Date.now() - start);
```

### User Context

Track events with user information:

```typescript
analytics.trackUser(userId, 'action_performed', {
  feature: 'checkout',
  value: 99.99,
});
```

### Cloudflare Analytics Engine

Native integration with Cloudflare Analytics Engine:

```typescript
// Automatically uses Analytics Engine if available
const analytics = AnalyticsFactory.create(ctx, env);

// Falls back to HTTP endpoint if not available
```

## Production Results

From Kogotochki bot deployment:

### Before Fire-and-Forget
- Telegram callback response: **200-300ms**
- Users see "loading" spinner on buttons
- Analytics adds 30-50ms per request
- Risk of CPU timeout on free tier

### After Fire-and-Forget
- Telegram callback response: **50ms** (82% faster!)
- Instant button feedback
- Analytics adds **0ms** to response
- Well within free tier limits

### Real Example

```typescript
// Before: 280ms total response time
async function handleCallback(callback: CallbackQuery) {
  await processCallback(callback);        // 200ms
  await sendAnalytics(callback);          // 50ms
  await answerCallbackQuery(callback.id); // 30ms
  // Total: 280ms - User waits!
}

// After: 50ms response time
async function handleCallback(callback: CallbackQuery) {
  await answerCallbackQuery(callback.id); // 30ms - Immediate!
  
  analytics.track('callback', {...});     // 0ms - Non-blocking
  
  await processCallback(callback);        // 20ms (with caching)
  // Total: 50ms - Instant feedback!
}
```

## Best Practices

### 1. Acknowledge UI Actions First

```typescript
// ✅ Correct order
await answerCallbackQuery(id);  // First - instant feedback
analytics.track('callback');    // Second - non-blocking

// ❌ Wrong order
analytics.track('callback');    // Don't block UI
await answerCallbackQuery(id);  // Too late!
```

### 2. Batch Related Events

```typescript
const analytics = new AsyncAnalytics(ctx, {
  batching: true,
  batchSize: 50,
});

// Track multiple events efficiently
analytics.track('step_1_complete');
analytics.track('step_2_complete');
analytics.track('step_3_complete');

// Single network call for all events
analytics.flush();
```

### 3. Always Flush at Request End

```typescript
try {
  // Handle request...
  
} finally {
  // Always flush, even on error
  analytics.flush();
}
```

### 4. Track Errors Without Throwing

```typescript
analytics.trackError(error, {
  fatal: false,
  recovered: true,
});

// Continue processing despite error
```

### 5. Use Appropriate Batch Sizes

```typescript
// High-volume endpoint
const analytics = new AsyncAnalytics(ctx, {
  batchSize: 100,      // Larger batches
  flushInterval: 5000, // Less frequent
});

// Low-volume endpoint
const analytics = new AsyncAnalytics(ctx, {
  batchSize: 10,       // Smaller batches
  flushInterval: 1000, // More frequent
});
```

## Testing

```typescript
import { describe, it, expect, vi } from 'vitest';

describe('Async Analytics', () => {
  it('should not block response', async () => {
    const mockCtx = {
      waitUntil: vi.fn(),
    };
    
    const analytics = new AsyncAnalytics(mockCtx, {
      endpoint: 'https://analytics.test',
    });
    
    const start = Date.now();
    
    // Track 100 events
    for (let i = 0; i < 100; i++) {
      analytics.track('event', { i });
    }
    
    const duration = Date.now() - start;
    
    // Should complete instantly
    expect(duration).toBeLessThan(10);
    
    // Events queued for background processing
    expect(mockCtx.waitUntil).toHaveBeenCalled();
  });
});
```

## Migration Guide

### From Synchronous Analytics

```typescript
// Before
async function handle(request: Request) {
  await analytics.send('event', data); // Blocking
  return response;
}

// After  
function handle(request: Request, env: Env, ctx: ExecutionContext) {
  const analytics = new AsyncAnalytics(ctx);
  analytics.track('event', data); // Non-blocking
  return response;
}
```

### From Sentry

```typescript
// Before
Sentry.captureException(error); // Partially blocking

// After
analytics.trackError(error); // Fully non-blocking
```

## Performance Comparison

| Metric | Synchronous | Fire-and-Forget | Improvement |
|--------|------------|-----------------|-------------|
| Callback Response | 280ms | 50ms | **82%** |
| API Response | 150ms | 90ms | **40%** |
| CPU Time | 8-9ms | 3-4ms | **55%** |
| Network Calls | Blocking | Non-blocking | **100%** |
| Error Impact | Blocks response | No impact | **∞** |

## Common Pitfalls

### ❌ Don't await analytics

```typescript
// Wrong - defeats the purpose
await analytics.track('event');
```

### ❌ Don't forget ExecutionContext

```typescript
// Wrong - won't work without context
const analytics = new AsyncAnalytics(null);
```

### ❌ Don't track sensitive data

```typescript
// Wrong - PII in analytics
analytics.track('user_data', {
  password: user.password, // Never!
  creditCard: user.card,   // Never!
});
```

### ✅ Do track aggregated metrics

```typescript
// Correct - aggregated and anonymous
analytics.track('checkout_complete', {
  amount: order.total,
  items_count: order.items.length,
  payment_method: 'card', // Type, not details
});
```

## Summary

The Fire-and-Forget Analytics pattern is essential for production applications on Cloudflare Workers. By deferring analytics until after the response, you can achieve:

- **82% faster response times**
- **Better user experience** (instant UI feedback)
- **Lower CPU usage** (stay within free tier)
- **Higher reliability** (analytics errors don't affect users)

This pattern has been proven in production with millions of events tracked without impacting user experience.