import type { CommandHandler } from '@/types';
import { logger } from '@/lib/logger';
import { isFeatureEnabled } from '@/config/tiers';

export const askCommand: CommandHandler = async (ctx) => {
  const tier = ctx.env.TIER || 'free';
  
  // Check if AI is enabled for this tier
  if (!isFeatureEnabled('aiEnabled', tier)) {
    await ctx.reply(
      'üö´ AI features are not available in the free tier.\n\n' +
      'Upgrade to the paid tier to access:\n' +
      '‚Ä¢ AI-powered responses\n' +
      '‚Ä¢ Advanced text generation\n' +
      '‚Ä¢ Smart assistance'
    );
    return;
  }

  const prompt = ctx.match;
  
  if (!prompt || typeof prompt !== 'string' || prompt.trim().length === 0) {
    await ctx.reply(
      'üí≠ Please provide a question or prompt after the command.\n\n' +
      'Example: /ask What is the weather like today?'
    );
    return;
  }

  try {
    // Check if Gemini service is available
    if (!ctx.services?.gemini) {
      await ctx.reply('‚ùå AI service is not configured properly.');
      logger.error('Gemini service not available in context');
      return;
    }

    // Send typing indicator
    await ctx.replyWithChatAction('typing');

    // Generate response
    const response = await ctx.services.gemini.generateText(prompt);

    // Send the AI response
    await ctx.reply(response, {
      parse_mode: 'HTML',
    });

    logger.info('AI query processed', {
      userId: ctx.from?.id,
      promptLength: prompt.length,
      tier,
    });
  } catch (error) {
    logger.error('Error in ask command', { error, userId: ctx.from?.id });
    
    await ctx.reply(
      '‚ùå Sorry, I encountered an error while processing your request.\n' +
      'Please try again later.'
    );
  }
};